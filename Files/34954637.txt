yarn container running memory 
yarn container running memory specific container runs apache spark driver node part dont understand limiting drivers heap size 512mb error message yarn container complaining memory 1gb message validate yarn launching run xmx512m containers setup 1gb memory 5gb increments physical machines hosting yarn containers 32gb sshed physical machines alot free memory strange thing throwing outofmemory exceptions driver logs eventually sigterm yarn shuts nicely process inside yarn 512mb shouldnt outofmemory exception allocate 1gb yarn running 1024m heap time container crashed usage 5gb happened consistantly container capacity allocate 5gb 1gb limit logical physical machine 30gb free memory inside yarn container taking extra 512mb running cdh apache spark yarn version cluster upgraded oracle java8 people claiming default maxpermsize java8 changed 512mb yarn error message 

check href https www mapr blog resource allocation configuration spark yarn rel nofollow article great description theyre aware max 384m overhead heap memory calculating memory executors edit eshalev accepting answer elaborating found java8 memory scheme specifically compressedclasses reserve 1024mb metaspace larger previous versions allocate perm gen memory jmap heap pid examine app crashing allocating 1024mb heap requirements wastefull app crashing 