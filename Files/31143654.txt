data structures randomized queues 
working princetons algorithms part assignments implement randomized queue question implementation tradeoffs data structures strong question strong randomized queue similar stack queue item removed chosen uniformly random items data structure create generic data type randomizedqueue implements api catch implement dequeue operation iterator dequeue removes returns strong random element strong iterator iterates queue strong random order strong strong array implementation strong primary implementation array implementation identical implementation array queue randomness em query em dequeue operation simply select number randomly size array return item move item array position returned item approach order queue case matter dequeuing random order wondering time memory efficient dequeue random element array preserving order queue create array transfer data em query em iterator meet requirement returning elements randomly create array indices queue shuffle array knuth shuffle operation return elements indices queue involves creating array equal length queue missing efficient method strong class implementation strong implementation involves node class em query em case understand perform dequeue operation efficiently return random node change references adjacent nodes confounded return iterator returns nodes random order create queue nodes attached random order benefits data structure array readability ease implementation post kind long guys time read question 

array implementation em query em things remove random element move fill spot removed code move items youd decrease count average item moves removal removal bad wont adding removing items iterating fisher yates shuffle existing array start returning items front back reason make copy depends usage pattern envision adding removing items queue youre iterating things wonky dont make copy linked list approach random dequeue operation difficult implement efficiently order random item traverse list front items queue remove 85th item youll start front follow links remove youre double linked list potentially cut time half counting backwards end item removed halfway point horribly inefficient number items queue large imaging removing 000th item queue million items random iterator shuffle linked list place start iterating takes log time extra space problem iterating time youre adding removing ability make copy 