spring batch read file write map 
strong background strong fairly spring batch requirement ol li read file minumum million records csv pipe delimited li li load row file map key column domain object pojo li ol understand spring batch chunk oriented processing configures reader processor writer process number records governed commit interval scaled task executor reader adding layer multithreading partitioning strong question strong explained point load file map sake discussion lets implement itemwriter aggregates chunks map access itemwriter bean call getsomepojomap aggregated map records file holding map itemwriter doesnt feel concern concurrenthashmap degrade performance dont aggregate file map thread manner aggregate file map holding map writer concurrenthashmap 

make small improvements putting map separate bean lifetime writer bean map decouple readers map writer instance put map job scoped bean writer singleton instance job partitioned multiple threads assuming dont map shared jobs 