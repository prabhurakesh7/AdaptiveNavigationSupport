spark rdd generate javardd length 
part problem href https spark apache org docs api org apache spark sparkcontext html parallelize 28scala collection seq 20int 20scala reflect classtag rel nofollow docs undocumented parallelize leave reading books examples dont pertain create rdd length executing operations class class implement serializable function dont fixed length dataset front create figure create dummy array length parallelize pass function runs times approach valid spark starting defined data set words doc length count words defined parallelize map filter operation data case parallelize creation rdd elements description spark method dodrop takes pipelinkagedata returns dropresult thinking map flatmap call function href http stackoverflow questions build spark javardd list dropresult objects question worked thinking correct approach concern javardd corrrect needing call flatmapfunction dont flatmappedrdd flatten group arrays lists single array list flatten 

ol li approach work long serialized issues internal logic depending shared state li li approach current form doesnt make sense single record processed single partition means process completely sequential crash data doesnt fit single worker memory increasing number elements solve problem doesnt improve approach li li finally initialize empty rdd replacing identical href https github apache spark blob branch core src main org apache spark api function mappartitionsfunction rel nofollow generate required number objects partition li ol 